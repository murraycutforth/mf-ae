{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "# In this notebook, we will evaluate the results of the ellipse dataset training runs\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import json\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "from sys import path\n",
    "path.append('../../..')\n",
    "\n",
    "base_output_dir = pathlib.Path('../../../output/lassen')\n",
    "files = list(base_output_dir.glob('interfacial_ae_v5_*'))\n",
    "len(files)\n"
   ],
   "id": "c36a42830400267e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from src.interface_representation.interface_transformations import InterfaceRepresentationType",
   "id": "6abd735a66b9f718",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a1a56b377ea3680e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_loss_curve_from_file(outdir):\n",
    "    loss_path = outdir / 'loss_history.json'\n",
    "    with open(loss_path) as f:\n",
    "        loss_curve = json.load(f)\n",
    "    return loss_curve\n",
    "\n",
    "def load_preds(outdir):\n",
    "    pred_path = outdir / 'preds_75.npz'\n",
    "    preds = np.load(pred_path)['preds']\n",
    "    return preds\n",
    "\n",
    "def load_gt(outdir):\n",
    "    gt_path = outdir / 'gts_75.npz'\n",
    "    gt = np.load(gt_path)['gts']\n",
    "    return gt\n",
    "\n",
    "def load_interface_type(filename):\n",
    "    final_part = '_'.join(filename.stem.split('_')[-2:])\n",
    "    \n",
    "    str_to_type = {\n",
    "        '00_datadirtanh': InterfaceRepresentationType.TANH,\n",
    "        'datadirexact_sdf': InterfaceRepresentationType.SDF_EXACT,\n",
    "        'datadirapprox_sdf': InterfaceRepresentationType.SDF_APPROX,\n",
    "        'datadirtanh_sharp': InterfaceRepresentationType.TANH,\n",
    "        'datadirtanh_smooth': InterfaceRepresentationType.TANH\n",
    "    }\n",
    "    \n",
    "    return str_to_type[final_part]\n",
    "\n",
    "def load_epsilon(filename):\n",
    "    final_part = '_'.join(filename.stem.split('_')[-2:])\n",
    "    \n",
    "    str_to_epsilon = {\n",
    "        '00_datadirtanh': 1/64,\n",
    "        'datadirexact_sdf': None,\n",
    "        'datadirapprox_sdf': None,\n",
    "        'datadirtanh_sharp': 1/128,\n",
    "        'datadirtanh_smooth': 1/32,\n",
    "    }\n",
    "    \n",
    "    return str_to_epsilon[final_part]\n",
    "\n",
    "\n",
    "def filename_to_plot_label(filename):\n",
    "    final_part = '_'.join(filename.stem.split('_')[-2:])\n",
    "    \n",
    "    str_to_label = {\n",
    "        '00_datadirtanh': 'Tanh 1/64',\n",
    "        'datadirexact_sdf': 'Exact SDF',\n",
    "        'datadirapprox_sdf': 'Approx. SDF',\n",
    "        'datadirtanh_sharp': 'Tanh 1/128',\n",
    "        'datadirtanh_smooth': 'Tanh 1/32'\n",
    "    }\n",
    "    \n",
    "    return str_to_label[final_part]\n",
    "\n",
    "\n",
    "def compute_phi_sharp_from_tanh(phi):\n",
    "    return np.heaviside(phi - 0.5, 1)\n",
    "\n",
    "\n",
    "def compute_phi_sharp_from_sdf(psi):\n",
    "    return np.heaviside(-psi, 1)\n",
    "\n",
    "\n",
    "def dice_coefficient(gt_patch, pred_patch, level: float = 0.5):\n",
    "    \"\"\"Returns the dice coefficient of foreground region, obtained by thresholding the images at level\n",
    "    \"\"\"\n",
    "    gt_patch = gt_patch > level\n",
    "    pred_patch = pred_patch > level\n",
    "    intersection = np.sum(gt_patch * pred_patch)\n",
    "    union = np.sum(gt_patch) + np.sum(pred_patch)\n",
    "    return 2 * intersection / union\n",
    "\n",
    "\n",
    "def hausdorff_distance(gt_patch, pred_patch, level: float = 0.5):\n",
    "    \"\"\"Returns the Hausdorff distance of the foreground region, obtained by thresholding the images at level\n",
    "\n",
    "    Note:\n",
    "        The distance is in units of voxels, assumes isotropic voxels\n",
    "\n",
    "    Args:\n",
    "        gt_patch: Ground truth patch\n",
    "        pred_patch: Predicted patch\n",
    "        level: Threshold level\n",
    "        max_num_points: Maximum number of points to use in the distance calculation (for speed purposes)\n",
    "    \"\"\"\n",
    "    gt_patch = gt_patch > level\n",
    "    pred_patch = pred_patch > level\n",
    "\n",
    "    gt_indices = np.argwhere(gt_patch) * 1 / 64\n",
    "    pred_indices = np.argwhere(pred_patch) * 1 / 64\n",
    "\n",
    "    if len(gt_indices) == 0 or len(pred_indices) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    h_1 = directed_hausdorff(gt_indices, pred_indices)[0]\n",
    "    h_2 = directed_hausdorff(pred_indices, gt_indices)[0]\n",
    "    return max(h_1, h_2)\n",
    "\n",
    "\n",
    "def get_phi_sharp_pred_and_gt(pred, gt, interface_type):\n",
    "    if interface_type == InterfaceRepresentationType.TANH:\n",
    "        pred = compute_phi_sharp_from_tanh(pred)\n",
    "        gt = compute_phi_sharp_from_tanh(gt)\n",
    "    elif interface_type == InterfaceRepresentationType.SDF_EXACT:\n",
    "        pred = compute_phi_sharp_from_sdf(pred)\n",
    "        gt = compute_phi_sharp_from_sdf(gt)\n",
    "    elif interface_type == InterfaceRepresentationType.SDF_APPROX:\n",
    "        pred = compute_phi_sharp_from_sdf(pred)\n",
    "        gt = compute_phi_sharp_from_sdf(gt)\n",
    "    else:\n",
    "        raise ValueError('Unknown interface type')\n",
    "    return pred, gt\n",
    "    "
   ],
   "id": "6bc059ec2ffda7b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2dcafd01dbe6a9d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "files",
   "id": "6f565814acfadfb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "plot_label_to_data = {}\n",
    "\n",
    "for file in files:\n",
    "    preds = load_preds(file)\n",
    "    gts = load_gt(file)\n",
    "    \n",
    "    interfacetype = load_interface_type(file)\n",
    "    plot_label = filename_to_plot_label(file)\n",
    "    epsilon = load_epsilon(file)\n",
    "    \n",
    "    print(interfacetype, epsilon)\n",
    "    \n",
    "    assert len(preds) == len(gts)\n",
    "    \n",
    "    means = []\n",
    "    dices = []\n",
    "    hds = []\n",
    "    \n",
    "    for pred, gt in zip(preds, gts):\n",
    "        pred, gt = get_phi_sharp_pred_and_gt(pred, gt, interfacetype)\n",
    "        \n",
    "        mse = np.mean((pred - gt)**2)\n",
    "        means.append(mse)\n",
    "        \n",
    "        dice = dice_coefficient(gt, pred)\n",
    "        dices.append(dice)\n",
    "        \n",
    "        hd = hausdorff_distance(gt, pred)\n",
    "        hds.append(hd)\n",
    "        \n",
    "    plot_label_to_data[plot_label] = {\n",
    "        'MSE': means,\n",
    "        'Dice': dices,\n",
    "        'Hausdorff': hds\n",
    "    }\n",
    "        \n",
    "    "
   ],
   "id": "e8d24d41c83e161b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For each metric, create a set of box plots with interface type on the x-axis\n",
    "    \n",
    "# For each metric, create a set of box plots with interface type on the x-axis\n",
    "\n",
    "metrics = ['MSE', 'Dice', 'Hausdorff']  # Add 'Hausdorff' if needed\n",
    "higher_or_lower = ['lower', 'higher', 'lower']\n",
    "fig, axs = plt.subplots(1, len(metrics), figsize=(18, 6))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    data = [plot_label_to_data[label][metric] for label in plot_label_to_data]\n",
    "    labels = list(plot_label_to_data.keys())\n",
    "    axs[i].boxplot(data, tick_labels=labels)\n",
    "    axs[i].set_title(f'{metric} ({higher_or_lower[i]} better)')\n",
    "    axs[i].set_ylabel(metric)\n",
    "    axs[i].spines['top'].set_visible(False)\n",
    "    axs[i].spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c6cecb8bfe6e98fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f034e43626c7bf03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compare droplet PDFs for gt/pred, for each interface type\n",
    "from scipy.ndimage import label\n",
    "\n",
    "def compute_droplet_pdf(arr):\n",
    "    # Assume that arr is binary. Label connected components, and return the histogram of the sizes\n",
    "    labeled_arr, num_labels = label(arr)\n",
    "    sizes = np.bincount(labeled_arr.ravel())\n",
    "    return sizes[1:]\n",
    "\n",
    "plot_label_to_data = {}\n",
    "\n",
    "for file in files:\n",
    "    preds = load_preds(file)\n",
    "    gts = load_gt(file)\n",
    "    \n",
    "    interfacetype = load_interface_type(file)\n",
    "    plot_label = filename_to_plot_label(file)\n",
    "    epsilon = load_epsilon(file)\n",
    "    \n",
    "    print(interfacetype, epsilon)\n",
    "    \n",
    "    assert len(preds) == len(gts)\n",
    "    \n",
    "    pred_sizes = []\n",
    "    gt_sizes = []\n",
    "    \n",
    "    for pred, gt in zip(preds, gts):\n",
    "        pred, gt = get_phi_sharp_pred_and_gt(pred, gt, interfacetype)\n",
    "        \n",
    "        pred_size = compute_droplet_pdf(pred)\n",
    "        gt_size = compute_droplet_pdf(gt)\n",
    "        \n",
    "        pred_sizes.extend(pred_size)\n",
    "        gt_sizes.extend(gt_size)\n",
    "        \n",
    "    plot_label_to_data[plot_label] = {\n",
    "        'gt': gt_sizes,\n",
    "        'pred': pred_sizes\n",
    "    }\n",
    "        \n",
    "        "
   ],
   "id": "c51756e86a4e19ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6132e8ec4b375d60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f3de8275d28ec281",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bf783566ebcdc658",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Plot the droplet PDFs\n",
    "fig, axs = plt.subplots(1, len(plot_label_to_data), figsize=(18, 6))\n",
    "\n",
    "for i, label in enumerate(plot_label_to_data):\n",
    "    data = plot_label_to_data[label]\n",
    "    axs[i].hist(data['gt'], bins=50, alpha=0.5, label='GT')\n",
    "    axs[i].hist(data['pred'], bins=50, alpha=0.5, label='Pred')\n",
    "    axs[i].set_title(label)\n",
    "    axs[i].set_xlabel('Droplet size')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].legend()\n",
    "    axs[i].spines['top'].set_visible(False)\n",
    "    axs[i].spines['right'].set_visible(False)\n"
   ],
   "id": "6d5675d809f5e760",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "\n",
    "- The performance metrics show generally better results for the exact SDF, worse for the approximate SDF, and no significant difference between the tanh interfaces. But all have very high reconstruction accuracy.\n",
    "- The comparison of droplet size PDFs is not meaningful on the synthetic data, as there is only 1 droplet per volume\n",
    "\n",
    "# Next steps\n",
    "\n",
    "- Repeat each run for 3 random seeds to get uncertainty estimates in metrics due to training process\n",
    "- Add heaviside interface representation\n",
    "- Try a new synthetic dataset comprised of a varying number (e.g. 1-10) of spheres with random radii and positions, as the ellipse dataset is too simple \n",
    "- Sample droplet radii from log-normal distribution, which is more representative of atomisation? Choose random max number of droplets (40) and then sample random radius and centre, and accept if no overlap with existing droplets.\n",
    "- Stick with pure AE, but future work with ROM would want to use beta-VAE.\n",
    "- Compare activation functions for the AE\n",
    "- Can we look at network depth vs. performance?\n",
    "- Push to 4 downsamples and 4 upsamples, "
   ],
   "id": "321c23b1de1720cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To be more concrete, we will:\n",
    "- Create a V8 dataset, where the droplet radii are log-normally distributed and there is no overlap\n",
    "- Re-create the V5 dataset with half the number of samples, change epochs to 100, and add two new types of interface representation\n",
    "\n",
    "Tonight: run + upload V5, upload V7, create V8 dataset"
   ],
   "id": "998f9f8de32747e1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
